### Ai reasoning remains task-specific

Ai reasoning remains tasks-specific and lacks metacognition (e.g., understanding its own limitations.) This may be why LLMs oblige almost any task even though they might be incapable of actually accomplishing said task. 

### Ai experiences cognitife dissonance

Mahzarin Banaji Richard Clarke Cabot Professor of Social Ethics Department of Psychology, Harvard University Abstract: Large Language Models (LLMs) show emergent patterns that mimic human cognition. We explored whether they also mirror other, less deliberative human psychological processes. Drawing upon classical theories of cognitive consistency, two preregistered studies tested whether GPT-4o changed its attitudes toward Vladimir Putin in the direction of a positive or negative essay it wrote about the Russian leader. Indeed, GPT displayed patterns of attitude change mimicking cognitive dissonance effects in humans. Even more remarkably, the degree of change increased sharply when the LLM was offered an illusion of choice about which essay (positive or negative) to write, suggesting that GPT-4o manifests a functional analog of humanlike selfhood. The exact mechanisms by which the model mimics human attitude change and self-referential processing remain to be understood.

(())